{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# TP4 : Techniques avancées\n",
    "\n",
    "Dans ce TP, vous allez mettre en pratique tout ce que vous avez appris !\n",
    "\n",
    "Ce TP sera **À RENDRE** sur Moodle :\n",
    "- Fichier notebook (`tp4.ipynb`) complété avec vos réponses\n",
    "- Fichier `models_results.csv` détaillant les résultats de vos expérimentations (voir Exercice 1, Q5 et Q6)\n",
    "- Fichier `predictions.csv` contenant les prédictions de votre meilleur modèle sur les données d'utilisation (voir Exercice 1, Q7)\n",
    "\n",
    "Il comptera pour **5 points** dans votre note de TP de l'UE, principalement déterminé en fonction du F2-score de vos prédictions sur les données d'utilisation (dont vous n'aurez pas les labels...).\n",
    "Exemple : vous obtenez un F2-score de 0.68 sur les données d'utilisation, vous obtiendrez $0.68 * 5 = 3.4$ points.\n",
    "\n",
    "Le prof reste souverain et s'autorise à baisser ou invalider la note si votre fichier notebook (`tp4.ipynb`) contient de la triche et/ou ne correspond pas aux résultats que vous fournissez ! Soyez donc honnête :-)\n",
    "\n",
    "Dans la limite de l'utilisation des données **de \"prototypage\"** fournies, vous êtes autorisés à utiliser toutes les techniques vues en cours : encodages, normalisations, équilibrages, suppression ou remplacement des données manquantes, ...\n",
    "\n",
    "Les données dites \"de déploiement\" (ou d'utilisation) doivent être considérées comme inaccessibles : vous ne devrez les utiliser que pour faire vos prédictions finales. Comme si vous les receviez une fois votre modèle de ML entraîné et déployé sur un serveur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce TP, on se place dans la situation de *data scientists* dans un hôpital. Vos collègues médecins essaient de détecter la présence d'une maladie cardiaque à partir de données sur les patients, obtenues par divers examens médicaux.\n",
    "\n",
    "Votre responsable hiérarchique veut que vous entraîniez un modèle de ML qui sera capable de prédire la présence de cette maladie, afin d'accélérer le traitement des patients et d'éviter le recours à des examens complémentaires beaucoup plus coûteux.\n",
    "\n",
    "On veut donc identifier le plus possible de patients malades (= maximiser le rappel !) pour laisser mourir le moins de patients possibles, tout en évitant de prédire les patients sains comme malade (= éviter que la précision ne soit de 0 !), sinon cela prendra trop de temps et coûtera trop cher... Nous utiliserons donc un F2-score comme métrique principale de sélection du meilleur modèle. Les autres métriques seront calculées et mémorisées à titre indicatif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description des données :\n",
    "\n",
    "| Nom | Description |\n",
    "|-----|-------------|\n",
    "| age | Âge du patient en années |\n",
    "| sex | Sexe du patient (`male` / `female`) |\n",
    "| chest pain | Type de douleur dans la poitrine ressentie |\n",
    "| resting blood pressure (mm Hg) | Pression sanguine au repos |\n",
    "| cholestoral (mg/dl) | Taux de choléstérol dans le sang |\n",
    "| fasting blood sugar > 120 mg/dl | Est-ce que le taux de glucose dans le sang après 8h à jeûn dépasse une valeur normale ? |\n",
    "| resting electrocardiograph | Présence d'une anomalie à l'électrocardiographe (ECG) au repos (`normal` : pas d'anomalie, `abnormal` : anomalie ST-T, `hypertrophy` : probable hypertrophie du ventricule gauche) |\n",
    "| max heart rate | Nombre maximum de battements cardiaques par minutes durant un exercice de résistance à l'effort (ex : vélo) |\n",
    "| exercise induced angina | Est-ce que l'exercice de résistance à l'effort a entraîné une douleur à la poitrine ? |\n",
    "| oldpeak | Dépression du segment ST de l'ECG lors de l'exercice de résistance à l'effort (relativement à l'ECG au repos) |\n",
    "| slope | Forme du segment ST de l'ECG (`upsloping` : hausse, `flat` : plat, `downsloping` : baisse) |\n",
    "| number of colored vessels by fluoroscopy | Le nombre d'artères majeures colorées par fluoroscopie (rayons X ou CT-scan) |\n",
    "| thalassemia | Présence d'une maladie sanguine (`3` : normal, `6` : maladie irréversible, `7` : maladie réversible)\n",
    "| **class** | **Cible de prédiction** : présence (`disease`) ou absence (`no disease`) d'un problème cardiaque |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 - Prise en main des données et préparation des fichiers de réponses\n",
    "\n",
    "J'attends un certain format dans vos fichiers de réponses (`models_results.csv` et `predictions.csv`) ; cet exercice va vous faire implémenter les fonctions permettant de remplir ces fichiers comme attendu.\n",
    "\n",
    "Comme vu dans le CM4, lorsque l'on prototype et expérimente sur divers algorithmes de ML, il est important de retenir les scores obtenus pour chaque algorithme, chaque préparation de données, et chaque *seed* (graine aléatoire). Cela permettra de sélectionner le meilleur modèle une fois les expérimentations effectuées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Chargez le fichier `data_prototyping.csv` dans un *DataFrame* `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Votre réponse ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Faites une EDA minimale : quelles sont les colonnes, quels sont leurs types de données ? Quelles sont les valeurs uniques pour chaque colonne catégorielle ? Existe-t-il des valeurs manquantes ?\n",
    "\n",
    "Vous ferez une EDA plus poussée dans l'Exercice 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Votre réponse ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Séparez vos données en `df_train` + `df_test`. Vous êtes libre de choisir la proportion de données dans chaque jeu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Votre réponse ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. On veut préparer les données de manière à ce qu'elles soient utilisables par un algorithme de ML. Il existe plusieurs façons de les préparer, comme on l'a vu au TP2 (c'est subjectif !). Chaque façon peut donner des performances différentes ; certains algorithmes fonctionneront mieux avec certaines façons que d'autres...\n",
    "\n",
    "Implémentez la fonction `prepare_data_v1(df)` qui prépare les données d'un *DataFrame* en entrée, de manière la plus simple possible : je recommande un **encodage ordinal** pour commencer et pouvoir tester rapidement vos algorithmes. Supprimez les colonnes contenant trop de NAs (>50%) pour simplifier également, ainsi que les lignes contenant au moins 1 NA.\n",
    "\n",
    "**Attention** : on rappelle que cet encodage fait perdre toute capacité d'interprétation s'il est utilisé sur une variable qui n'a pas de relation d'ordre ! Certains algorithmes auront également de mauvaises performances car ils calculeront une relation statistique qui n'existe pas... Ce n'est pas grave pour cet exercice, cela permet de tester rapidement un algorithme sur nos données.\n",
    "\n",
    "**Attention²** : Votre fonction devra fonctionner sur des sous-ensembles de données ! En effet, en pratique vous ne connaîtrez pas vos données d'utilisation avant d'avoir déployé votre modèle... Votre fonction de préparation devra donc être appliquée sur les données d'utilisations indépendamment des données de prototypage. Faites particulièrement attention à **l'ordre de vos encodages** ! Si votre fonction encode `normal=1, abnormal=2` dans vos données de prototypage, puis `abnormal=1, normal=2` dans vos données d'utilisation, votre modèle de ML prédira n'importe quoi... Je recommande de faire votre encodage à la main, en utilisant par exemple [`df.replace()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html) pour vous assurer que l'encodage sera **cohérent**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Votre réponse ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous avez bien séparés vos données et implémenté la fonction de préparation, la prochaine cellule devrait s'exécuter sans problème. Notez bien que les données de test ne sont pas préparées en même temps que les données d'entraînement !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_v1, df_test_v1 = prepare_data_v1(df_train), prepare_data_v1(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Implémentez la méthode `evaluate_model(df_train, df_test, data_name, model_name, model_class, hyperparameters)`. Cette méthode devra instancier un estimateur (`model_class`) avec les hyperparamètres demandés, l'entraîner sur les données d'entraînement fournies, puis calculer les métriques suivantes sur les données de test fournies :\n",
    "\n",
    "- F2-score\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "\n",
    "Vous pouvez utiliser les méthodes de Scikit-learn pour ces [métriques](https://scikit-learn.org/stable/api/sklearn.metrics.html) (attention à la classe d'intérêt ! Par défaut, Scikit utilise `1` comme classe d'intérêt, mais vous pouvez en spécifier une autre via l'argument `pos_label`).\n",
    "\n",
    "Votre fonction devra renvoyer un *DataFrame* contenant les colonnes suivantes :\n",
    "- ModelName : le nom du modèle utilisé (algorithme)\n",
    "- Data : le nom de la méthode de préparation des données\n",
    "- Hyperparamètres : le dictionnaire des hyperparamètres\n",
    "- RandomSeed : la graine aléatoire utilisée pour instancier et entraîner le modèle\n",
    "- Score_f2 : la métrique de F2-Score sur les prédictions de test\n",
    "- Score_precision : la métrique de Precision sur les prédictions de test\n",
    "- Score_recall : la métrique de Rappel sur les prédictions de test\n",
    "- Score_accuracy : la métrique d'Accuracy (% de prédictions correctes) sur les prédictions de test\n",
    "- TrainedEstimator : l'instance du modèle entraînée (pour réutilisation ultérieure si besoin)\n",
    "\n",
    "\n",
    "On vous donne le squelette de cette fonction, à vous de remplir les trous !\n",
    "\n",
    "```python\n",
    "def evaluate_model(df_train, df_test, data_name, model_name, model_class, hyperparameters):\n",
    "    X_train = # À COMPLÉTER\n",
    "    Y_train = # À COMPLÉTER\n",
    "    X_test = # À COMPLÉTER\n",
    "    Y_test = # À COMPLÉTER\n",
    "\n",
    "    # On génère une graine aléatoire ... de manière aléatoire :-)\n",
    "    seed = np.random.randint(0, 2**32 - 1)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # On instancie l'algorithme avec les hyperparamètres demandés\n",
    "    # En pratique, si on a par exemple `model_class=LogisticRegression` et\n",
    "    # # `hyperparameters={ 'n_iter': 100, 'eta0': 0.1 }`, c'est équivalent à faire\n",
    "    # `LogisticRegression(n_iter=100, eta0=0.1)`\n",
    "    estimator = model_class(**hyperparameters)\n",
    "\n",
    "    # À COMPLÉTER : entraînez le modèle !\n",
    "    \n",
    "    y_pred = # À COMPLÉTER : calculez les prédictions sur les données de test\n",
    "\n",
    "    return pd.DataFrame([{\n",
    "        'ModelName': model_name,\n",
    "        'Data': data_name,\n",
    "        'Hyperparameters': hyperparameters,\n",
    "        'RandomSeed': seed,\n",
    "        'Score_f2': # À COMPLÉTER\n",
    "        'Score_precision': # À COMPLÉTER\n",
    "        'Score_recall': # À COMPLÉTER\n",
    "        'Score_accuracy': # À COMPLÉTER\n",
    "        'TrainedEstimator': estimator\n",
    "    }])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Votre réponse ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous avez bien implémenté la fonction `evaluate_model()` et que vos données sont bien préparées, l'expérimentation ci-dessous devrait fonctionner et vous afficher le résultat d'une Régression Logistique (sur des données préparées \"naïvement\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# `'v1'` réfère à la fonction `prepare_data_v1`\n",
    "results = evaluate_model(\n",
    "    df_train_v1,\n",
    "    df_test_v1,\n",
    "    'v1',\n",
    "    'LogisticRegression',\n",
    "    LogisticRegression,\n",
    "    {'penalty': None, 'max_iter': 1000},\n",
    ")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Enregistrez les résultats de l'expérimentation ci-dessus dans un fichier `models_results.csv`.\n",
    "\n",
    "On vous donne, pour vous aider, une fonction qui ajoute automatiquement les résultats sans effacer les précédents ! :-)\n",
    "\n",
    "Note : il est très important d'enregistrer vos résultats à chaque expérimentation, pour ne pas \"perdre\" ces résultats, en particulier si vous redémarrez votre notebook. Dans la suite du TP, utilisez cette fonction **chaque fois** que vous faites une nouvelle expérimentation ! En pratique, on utilise souvent des outils dédiés tels que ceux présentés en cours (MLFlow, Weights and Biases, Aimstack, ...).\n",
    "\n",
    "Le fichier `models_results.csv` sera à rendre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_results(results):\n",
    "    with open('models_results.csv', 'a') as f:\n",
    "        # Quand le fichier est vide, il faut préciser les colonnes ;\n",
    "        # si on a au moins une ligne, il ne faut pas répéter les noms des colonnes...\n",
    "        header = f.seek(0, 2) == 0\n",
    "        # On ne veut pas écrire la colonne `TrainedEstimator` (c'est un objet Python !)\n",
    "        columns = [\n",
    "            'ModelName', 'Data', 'Hyperparameters', 'RandomSeed', 'Score_f2', \n",
    "            'Score_precision', 'Score_recall', 'Score_accuracy',\n",
    "        ]\n",
    "        results.to_csv(f, header=header, columns=columns, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Votre réponse ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Pour vous montrer ce qu'on attend pour les prédictions à rendre, faites les prédictions sur le modèle de Régression Logistique de la précédente expérimentation, sur les données \"de déploiement\", préparées via la façon 'v1'.\n",
    "\n",
    "On vous fournit une fonction pour écrire les prédictions dans un fichier `predictions.csv`.\n",
    "\n",
    "**Attention** : dans la suite du TP, vous ne devrez faire les prédictions sur ces données de déploiement que pour votre meilleur modèle et votre meilleure préparation de données ! De toute façon vous n'aurez pas les labels, donc vous ne saurez pas si vos prédictions sont bonnes ou non...\n",
    "\n",
    "1. Récupérez le modèle entraîné (`TrainedEstimator`) de votre meilleure expérimentation (pour l'instant vous n'en avez qu'une seule : `results`). Si vous redémarrez le notebook d'ici la fin du TP, vous devriez avoir toutes les informations dans le fichier `models_results.csv` (la classe à utiliser, la fonction de préparation de données, les hyperparamètres, et la *seed* aléatoire) pour ré-entraîner le même modèle.\n",
    "2. Puis, appelez la fonction `write_predictions()` avec en paramètre votre fonction de préparation de données (ici, `prepare_data_v1`) et votre modèle entraîné.\n",
    "\n",
    "Cette fonction se charge automatiquement de lire les données, les préparer, faire les prédictions, et les écrire dans le fichier de sortie `predictions.csv`. Elle gère également les prédictions manquantes si votre fonction de préparations de données supprime des lignes (NAs).\n",
    "\n",
    "Le fichier `predictions.csv` sera à rendre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions(prepare_data_function, estimator):\n",
    "    df_deployment = pd.read_csv('data_deployment.csv')\n",
    "    df_deployment_prepared = prepare_data_function(df_deployment)\n",
    "    # /!\\ Si la fonction de préparation des données supprime des lignes\n",
    "    # (par exemple à cause de la gestion des NAs), on va se retrouver \n",
    "    # avec moins de prédictions qu'on a de lignes...\n",
    "    # On doit matcher chaque prédiction avec sa ligne correspondante\n",
    "    handled_lines = df_deployment_prepared.index\n",
    "\n",
    "    # On prédit pour chaque ligne des données préparées\n",
    "    predictions = estimator.predict(df_deployment_prepared)\n",
    "    # On ré-assimile aux numéros de lignes des données originales\n",
    "    predictions = pd.Series(predictions, index=handled_lines)\n",
    "\n",
    "    # On ajoute la colonne aux données originales ; puisqu'on a indexé les\n",
    "    # prédictions, les prédictions manquantes seront automatiquement remplacées par NaN\n",
    "    df_deployment['predictions'] = predictions\n",
    "    # On écrit le fichier\n",
    "    df_deployment.to_csv('predictions.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Votre réponse ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 : à vous de jouer !\n",
    "\n",
    "Vous êtes maintenant libres de vos choix pour identifier le meilleur modèle et la meilleure préparation de données !\n",
    "\n",
    "N'oubliez pas d'enregistrer chaque expérimentation via la méthode `append_results()`.\n",
    "\n",
    "**Attention** : une fois que vous avez expérimenté avec une façon de préparer de vos données (par exemple, `prepare_data_v1()`), vous NE DEVEZ PLUS modifier cette fonction ! Sinon, vous rendez irreproductibles toutes vos expérimentations précédentes ! Dans la pratique, on utilise souvent des Data Version Control (DVC) et des Version Control System (VCS, exemple : Git) pour s'assurer de mémoriser ce qu'on a fait et de pouvoir y revenir.\n",
    "\n",
    "Vous devrez donc implémenter des fonctions `prepare_data_v2()`, `prepare_data_v3()`, etc. (autant que nécessaires pour tester toutes vos idées) !\n",
    "\n",
    "On vous donne quelques pistes d'exploration ci-dessous pour vous aider ...\n",
    "Les questions suivantes sont données à titre d'indication, vous n'êtes pas obligés de toutes les faire, ni de suivre cet ordre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Faites une EDA plus poussée. Quelles sont les données catégorielles ? Quelles valeurs peuvent-elles prendre ? Existe-t-il des données manquantes ?\n",
    "\n",
    "Astuce : les types de données que Pandas vous retourne peuvent ne pas être cohérents ! Vérifiez avec la description des données fournie pour détecter si des colonnes devraient plutôt avoir un autre type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. L'encodage ordinal est un moyen rapide de tester un algorithme (prototypage), mais qui montre vite ses limites, surtout pour les données sans relation d'ordre. Quels autres encodages pouvez-vous utiliser ?\n",
    "\n",
    "Astuce : il vaut peut-être le coup d'essayer plusieurs formes d'encodages pour voir l'impact sur les performances...\n",
    "\n",
    "On rappelle quelques méthodes d'encodage :\n",
    "\n",
    "- Encodage ordinal\n",
    "- Encodage one-hot\n",
    "- Encodage binaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Quelles sont les échelles de chaque colonne numérique (valeurs min vs max) ? Quelles sont les distributions de ces colonnes ? Quelles normalisations pouvez-vous utiliser ?\n",
    "\n",
    "Astuce : il vaut peut-être le coup d'essayer plusieurs formes de normalisations pour voir l'impact sur les performances...\n",
    "\n",
    "On rappelle quelques méthodes de normalisation :\n",
    "- Linéaire (min-max)\n",
    "- Z-score\n",
    "- Log\n",
    "\n",
    "Vous pouvez utiliser du *clipping* en plus de chacune des méthodes de normalisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Existe-t-il des données manquantes ? Quelles colonnes ont beaucoup de données manquantes ? Combien de lignes possèdent au moins une valeur manquante ?\n",
    "\n",
    "**Attention** : si votre fonction de préparation de données supprime les lignes contenant 1 valeur manquante (NA), vous allez supprimer des lignes du jeu de données \"de déploiement\" (ou d'utilisation). Ce qui veut dire que vous ne ferez pas de prédictions sur ces lignes, ce qui baissera forcément votre score ! Durant la phase d'entraînement, on peut se permettre de supprimer les valeurs manquantes si on pense qu'elles vont empêcher l'apprentissage ; mais, en déploiement, quand votre modèle sera utilisé par des personnes extérieures, vous pouvez difficilement vous permettre de rejeter des entrées... (Ou alors, vous risquez que vos utilisateurs finissent par ne plus utiliser votre modèle)\n",
    "\n",
    "Vous pouvez essayer de supprimer les données manquantes, ou de les remplacer...\n",
    "\n",
    "On rappelle quelques méthodes de remplacement :\n",
    "- Par un valeur \"sentinelle\" indiquant une absence (par exemple, `-1`)\n",
    "- Par moyenne, médiane, ou mode (valeur fixe)\n",
    "- Par *forward-fill* ou *backward-fill*\n",
    "- Par apprentissage non-supervisé\n",
    "\n",
    "Les méthodes par valeur fixe (moyenne, médiane, mode) ou par données existantes (forward-fill, backward-fill) peuvent être utilisées en corrélation avec d'autres colonnes, par exemple en faisant un `groupby`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. On a essayé une Régression Logistique, mais il existe d'autres algorithmes de classification ! Lesquels paraissent intéressants pour cette tâche ?\n",
    "Comparez ces algorithmes, sur vos différentes façons de préparer vos données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Chaque algorithme possède un certain nombre d'hyperparamètres, impactant les performances. Comparez les performances de différents hyperparamètres, pour chaque modèle.\n",
    "\n",
    "La documentation de Scikit-learn liste les hyperparamètres dans le constructeur de chaque algorithme. Attention : cette liste est souvent plus étoffée que celle vue en cours, car Scikit propose des optimisations, mais laisse la configuration de ces optimisations au choix des utilisateurs..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Quelle est la fréquence de chaque classe ? Vous pouvez essayer de ré-équilibrer les données pour améliorer les performances.\n",
    "\n",
    "On rappelle quelques méthodes de ré-équilibrage :\n",
    "- *Downsampling* : diminution de la classe majoritaire jusqu'à atteindre la même proportion que la classe minoritaire.\n",
    "- *Upsampling* : répétition des individus de la classe minoritaire jusqu'à atteindre la même proportion que la classe majoritaire.\n",
    "- *Loss weighting* : on peut pondérer la fonction de *loss* pour rendre les erreurs sur la classe minoritaire plus coûteuses. Attention : cela suppose que la distribution des classes dans les données d'utilisation seront les mêmes ! Dans la pratique, vous ne pouvez pas en être certains...\n",
    "- Génération de données : on peut générer des données similaires aux données existantes, en espérent qu'elles soient suffisamment proches pour qu'elles représentent bien le phénomène que l'on cherche à modéliser. Attention : dans la pratique, c'est compliqué de générer des données pour modéliser un phénomène, sans avoir un modèle du phénomène ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Dans la fonction `evaluate_model()`, on vous fait initialement mesurer les performances de votre modèle sur les données de test. Or, en comparant les modèles sur ces données, on risque de choisir un modèle qui est trop spécialisé sur ces données, mais qui ne saura pas généraliser aux données d'utilisation ! On a vu en cours une technique pour éviter ce problème : la *cross-validation*. Vous pouvez implémenter une autre fonction `evaluate_model_cv()` qui suit le même principe mais qui utilise la *cross-validation* pour comparer les modèles.\n",
    "\n",
    "Astuce : votre fonction peut évaluer plusieurs modèles et retourner un *DataFrame* contenant plusieurs résultats, avec `pd.DataFrame([ {...}, {...}, {...} ])`, où chaque `{...}` est un dictionnaire comme celui de la fonction `evalute_model()`. Cela permettrait d'évaluer les modèles sur les mêmes *folds* de la *cross-validation*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. Vous pouvez essayer des méthodes ensemblistes.\n",
    "\n",
    "On rappelle les 3 principales catégories de méthodes ensemblistes vues en cours :\n",
    "- *Bagging*\n",
    "- *Boosting*\n",
    "- *Stacking*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N'oubliez pas de mettre à jour vos fichiers `models_results.csv` et `predictions.csv` !!!\n",
    "\n",
    "- `models_results.csv` à chaque expérimentation effectuée ;\n",
    "- et `predictions.csv` une fois votre meilleur modèle identifié.\n",
    "\n",
    "Ces fichiers sont à rendre sur Moodle avec votre fichier `tp4.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teaching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
